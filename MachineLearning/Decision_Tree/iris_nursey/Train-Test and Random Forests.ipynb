{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Model overfit?\n",
    "Let's assume at our iris nursey we have a leaky heating duct that we dont know about.  And the irises under that duct are warmer by a few degrees, just enough to inhibit their growth.  And there are a variety of different irises under that duct, so the effect is random across the three species.\n",
    "\n",
    "Because we dont know about it, this factor will not be in our model, so will act as a random effect that results in some irises being misclassified.  But we want 100% accuracy, so we continue to increase the model's depth, eventually reaching 100% accuracy.  That is a good thing, right?\n",
    "\n",
    "Remember that we dont know that it is the heating duct, and *neither does your model*.  It will use the included factors to try to classify.  If you push the model hard enough, it may, for example, identify a narrow combination of petal width and sepal length that explains those specific irises, but these arent *true* effects.  Instead you are using randomness to try to classify the results. But since that combination of features isn't systemic to irises, you will compromise the generizability of your model.  It will do *worse* in the future.\n",
    "\n",
    "Here is another way to think about it, using lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Overfit](model_fit.png \"Model Overfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads up the iris data and completes the feature engineering from the last class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and put it into a dataframe:\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "\n",
    "# set the column names:\n",
    "cols = ['sepal_length',\n",
    " 'sepal_width',\n",
    " 'petal_length',\n",
    " 'petal_width']\n",
    "df.columns = cols\n",
    "\n",
    "# The target identifies the species as 0, 1, or 2.  \n",
    "# Add target to our dataframe for later\n",
    "\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Add the actual names of the irises to the dataframe for reference\n",
    "df['species'] = 'Iris Setosa'\n",
    "df.loc[df.target == 1, 'species'] = 'Iris Versicolour' \n",
    "df.loc[df.target == 2, 'species'] = 'Iris Virginica'\n",
    "\n",
    "# Split the data into X and y dataframes for analysis\n",
    "X = df[['sepal_length',\n",
    " 'sepal_width',\n",
    " 'petal_length',\n",
    " 'petal_width']]\n",
    "\n",
    "names = ['Iris Setosa', 'Iris Versicolour', 'Iris Virginica']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that the species names were mapped correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>species</th>\n",
       "      <th>Iris Setosa</th>\n",
       "      <th>Iris Versicolour</th>\n",
       "      <th>Iris Virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "species  Iris Setosa  Iris Versicolour  Iris Virginica\n",
       "target                                                \n",
       "0                 50                 0               0\n",
       "1                  0                50               0\n",
       "2                  0                 0              50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.target, df.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "Random forests overcome decision trees' tendency to overfit--that is, to work well for a training dataset, but degrade when exposed to new data.  To overcome this limitation, an ensemble method--called 'random forests' are used.\n",
    "\n",
    "Random forests create dozens (or even hundreds) of randomized decision trees, using randomized subsets of data.  Each tree is therefore different, but the advantage is that the ensemble will do a better job of predicting than just one tree.  This power of crowds dramatically improves the efficacy of decision trees.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests choose a subset of features as well as a subset of dataframe rows to generate a new decision tree.  This process is then repeated dozens, hundreds, or even thousands of times.  The power of random forests is comparing the accuracy results across the generated trees.  Consistent results indicates that the model will generalize--that is, has not been overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "The following divides the dataset into 70\\% training and 30\\% testing.  We will use the train set to train our decision tree.  We will then run the *test* data set using clf object (which contains all parameters for the trained decision tree), to see how it performs on data that it has never seen.\n",
    "\n",
    "The train/test concept allows us to explore the generalizability of our model: if the model performance is consistent, this is evidence that the model generalizes--that is, is not overfit. This also indicates that we can be more confident on applying our model to classify new irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder: random_state will ensure you get the same results\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "        test_size = 0.3, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# generate 10 decision trees\n",
    "clf = RandomForestClassifier(n_estimators=10, verbose=0, bootstrap=True, max_depth=2, \\\n",
    "            random_state=42) \n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "preds = clf.predict(X_train)\n",
    "probs = clf.predict_proba(X_train)\n",
    "accuracy = round(clf.score(X_train,y_train)*100,2) # make it a percentage and round to 2 places\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model using the Train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts with 94.29\\% accuracy, which seems pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18235931 0.         0.292432   0.52520869]\n"
     ]
    }
   ],
   "source": [
    "# 'sepal_length', 'sepal_width', 'petal_length', 'petal_width'\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is perhaps a powerful result: this indicates the relative power of each of the included features in predicting the species of iris.  According to this, therefore, the relative contribution of each is: \n",
    "* sepal_length: 18.2\\%\n",
    "* sepal_width: 0\\%\n",
    "* petal_length: 29.2\\%\n",
    "* petal_width: 52.5\\%\n",
    "\n",
    "At least within our decision tree, the petal dimensions were by far the most important in classifying the iris species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Confusion Matrix to Gauge our Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    37\n",
       "1    37\n",
       "0    31\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we divided the data into test and train, the above represents 70\\% of our original data, or n=105. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the probability and prediction of each iris\n",
    "preds = clf.predict(X_train)\n",
    "probs = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  0,  0],\n",
       "       [ 0, 35,  2],\n",
       "       [ 0,  4, 33]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a powerful summary of our model's performance.  The rows represent the actual species (0,1,2), while the columns represent the predicted species.  The diagonal (upper left to lower right) indicates the correct classifications.  If our model is perfect, only the diagonals would have numbers: the rest would be 0.  \n",
    "\n",
    "The number 2 in the second row is an off-diagonal, so it is a misclassification.  The model predicted that the species was 2, but it was actually 1 (remember to start counting with 0!).  The other classification error is in row 3. Four Virginica irises (target=2) are being classified as Versicolor (target=2).  The accuracy of our tree, therefore, is:\n",
    "\n",
    "`(31+35+33)/105 = 94.29%`\n",
    "\n",
    "We can confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.9429.\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(X_train,y_train)\n",
    "print(\"Accuracy is: {:.4f}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results indicate that our trained model does a good job of classifying iris species.  The question, however, is: how well does it generalize?  If our model is too tied to this particular dataset, that is called _overfitting_.  It indicates that the model will not generalize to new irises.  \n",
    "\n",
    "This is a major concerns with decision trees, so we need to confirm that our model will generalize.  Fortunately, we withheld 30\\% of our data in the X_test data set, so we can now see how well the model performs with new data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the test data to test the generalizability of our model\n",
    "Now that we have trained a decision tree, let's test its generalizability by running it using the test data.  If the results are similar, we have a generalizable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.0000.\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(X_test,y_test)\n",
    "print(\"Accuracy is: {:.4f}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow.  No overfit here! The model actually performs _better_.The model actually did better on the test data than the train data.  This indicates that our model is not overfit and may generalize to other irises!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the probability and prediction of each iris\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Confusion Matrix to Gauge our Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0],\n",
       "       [ 0, 13,  0],\n",
       "       [ 0,  0, 13]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Our Model Indicates\n",
    "The results indicate that our model is not overfitted, so it is natural at this point to assume overfit is rarely a problem.  At least with regard to decision trees, that is not true.  _You should always train/test your decision tree models, to ensure your results are generalizable._ \n",
    "\n",
    "Please remember that I cherrypicked a data set that is known to be easy to classify, so the amount of signal is strong and the amount of randomness is very small.  In real life, of course, your data will likely have a lot of random effects, so you need to be careful of compromising generlizability by striving for perfection.\n",
    "\n",
    "Another reason we didnt have a problem is that we restricted the model depth to two.  You can always improve your decision tree's acuracy by adding more depth, but Turns out, the model will continue to improve if we add depth, but the iris dataset is popular _because_ the flowers are easily categorized.  Real data will rarely behave as well.  Just be prepared to train and test your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may wonder: where is our decision tree?  The answer is: which one?  We just generated a lot of decision trees, so there is no longer *just one tree.* Instead, we used an ensemble method to mitigate the effects of overfitting: in laymen's terms, we generated a large number of trees to improve its ability to predict new irises in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
